{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 112/132748 [00:00<02:13, 995.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting pretrain the rating matrix...\n",
      "starting ROM model\n",
      "Epoch 1 training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–‹         | 8560/132748 [00:07<01:48, 1146.58it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-790c559a4e95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Baby\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-790c559a4e95>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(category)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion_MUD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotalOut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;31m#             print(loss.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yingqiang/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yingqiang/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "# from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from heapq import heappush, heappop\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import evaluation\n",
    "import data_loader\n",
    "from model import MF, MUD\n",
    "\n",
    "def main(category):\n",
    "    params = dict()\n",
    "    params['lr'] = 0.001\n",
    "    params['batch_size'] = 16\n",
    "    params['epoch_limit'] = 1\n",
    "    params['w_decay'] = 1\n",
    "    params['negNum'] = 1000\n",
    "    params['epsilon'] = 1e-4\n",
    "    params['n_neg'] = 4\n",
    "    params['l_size'] = 32\n",
    "    params['gpu']=False\n",
    "\n",
    "    train, val, test = data_loader.read_data(category)\n",
    "    item_price = data_loader.get_price(category)\n",
    "    item_related = data_loader.read_related(category)\n",
    "    distribution = data_loader.get_distribution(category)\n",
    "    trainset = data_loader.TransactionData(train, item_related, \\\n",
    "                item_price, distribution)\n",
    "    valset = data_loader.UserTransactionData(val, item_price, \\\n",
    "                trainset.itemNum, trainset.userHist)\n",
    "    testset = data_loader.UserTransactionData(test, item_price, \\\n",
    "                trainset.itemNum, trainset.userHist)\n",
    "\n",
    "    Rating = MF(userLen = trainset.userNum, itemLen = trainset.itemNum,\\\n",
    "             params = params)\n",
    "    optimizer_r = opt.SGD(Rating.parameters(), lr = params['lr'], \\\n",
    "            weight_decay = params['w_decay'])\n",
    "\n",
    "    criterion_rating = nn.MSELoss(reduction = 'sum')\n",
    "    criterion_risk = nn.MSELoss(reduction = 'sum')\n",
    "    criterion_MUD = nn.LogSoftmax(dim=0)\n",
    "\n",
    "    trainset.set_negN(params['n_neg'])\n",
    "    trainLoader = DataLoader(trainset, batch_size = params['batch_size'], \\\n",
    "                            shuffle = True, num_workers = 0)\n",
    "    valset.set_negN(1000)\n",
    "    valLoader = DataLoader(valset, batch_size = 1, \\\n",
    "                            shuffle = True, num_workers = 0)\n",
    "    testset.set_negN(1000)\n",
    "    testLoader = DataLoader(testset, batch_size = 1, \\\n",
    "                            shuffle = True, num_workers = 0)\n",
    "\n",
    "    epsilon = params['epsilon']\n",
    "    epoch = 1\n",
    "    error = np.float('inf')\n",
    "\n",
    "    print(\"starting pretrain the rating matrix...\")\n",
    "    while epoch < params['epoch_limit']:\n",
    "        runningLoss = []\n",
    "        epoch += 1\n",
    "        print(\"Epoch \" + str(epoch) + \" training...\")\n",
    "        L = len(trainLoader.dataset)\n",
    "        pbar = tqdm(total=L)\n",
    "        for i, batchData in enumerate(trainLoader):\n",
    "            optimizer_r.zero_grad()\n",
    "            # get input\n",
    "            users = torch.LongTensor(batchData['user']).to(Rating.device)\n",
    "            items = torch.LongTensor(batchData['item']).to(Rating.device)\n",
    "            pre_r = Rating.forward(users, items)\n",
    "            r = torch.FloatTensor(batchData['rating']).to(Rating.device)\n",
    "\n",
    "            loss = criterion_rating(pre_r, r)\n",
    "            loss.backward()\n",
    "            optimizer_r.step()\n",
    "            runningLoss.append(loss.item())\n",
    "\n",
    "            pbar.update(users.shape[0])\n",
    "        pbar.close()\n",
    "        meanMSE = np.mean(np.array(runningLoss))\n",
    "        improvement = np.abs(error - meanMSE)\n",
    "        error = meanMSE\n",
    "        if improvement <= epsilon:\n",
    "            print('pre-train stop early')\n",
    "            break\n",
    "\n",
    "    model = MUD(userLen = trainset.userNum, itemLen = trainset.itemNum,\\\n",
    "             distribution = distribution, item_price = item_price, \\\n",
    "             RMF = Rating, params = params)\n",
    "    optimizer = opt.SGD(model.parameters(), lr = params['lr'], \\\n",
    "            weight_decay = params['w_decay'])\n",
    "\n",
    "    epsilon = params['epsilon']\n",
    "    epoch = 0\n",
    "    error = np.float('inf')\n",
    "\n",
    "    trainErrorList = []\n",
    "    valErrorList = []\n",
    "    valHistory = []\n",
    "    explodeTempreture = 3\n",
    "    convergenceTempreture = 3\n",
    "    print(\"starting ROM model\")\n",
    "    while epoch < params['epoch_limit']:\n",
    "        epoch += 1\n",
    "        print(\"Epoch \" + str(epoch) + \" training...\")\n",
    "        L = len(trainLoader.dataset)\n",
    "        pbar = tqdm(total = L)\n",
    "        for i, batchData in enumerate(trainLoader):\n",
    "            optimizer.zero_grad()\n",
    "            # get input\n",
    "            users = torch.LongTensor(batchData['user']).to(model.device)\n",
    "#             print(users.shape)\n",
    "            items = torch.LongTensor(batchData['item']).to(model.device)\n",
    "#             print(items.shape)\n",
    "            negItems = torch.LongTensor(batchData['negItem']).to(model.device).reshape(-1)\n",
    "#             print(negItems.shape)\n",
    "            \n",
    "            nusers = users.view(-1,1) \n",
    "            nusers = nusers.expand(nusers.shape[0], params['n_neg']).reshape(-1)\n",
    "#             print(nusers.shape)\n",
    "            \n",
    "            \n",
    "            pOut = model.forward(users,items).view(-1,1)\n",
    "#             print(pOut.shape)\n",
    "            \n",
    "            nOut = model.forward(nusers, negItems)\n",
    "            nOut = nOut.reshape(-1,params[\"n_neg\"])\n",
    "#             print(nOut.shape)\n",
    "            \n",
    "            totalOut = torch.cat((pOut,nOut),dim=1)\n",
    "#             print (totalOut.shape)\n",
    "            \n",
    "            loss = torch.mean(criterion_MUD(totalOut)[:,0])\n",
    "#             print(loss.shape)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update(users.shape[0])\n",
    "        pbar.close()\n",
    "        print(\"Epoch \" + str(epoch) + \" training risk...\")\n",
    "        pbar = tqdm(total = L)\n",
    "        for i, batchData in enumerate(trainLoader):\n",
    "            optimizer.zero_grad()\n",
    "            users = torch.LongTensor(batchData['user']).to(model.device)\n",
    "            items = torch.LongTensor(batchData['user']).to(model.device)\n",
    "\n",
    "            eu = model.EU(users,items)\n",
    "            ue = model.UE(users,items)\n",
    "\n",
    "            loss = criterion_risk(ue, eu)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update(users.shape[0])\n",
    "        pbar.close()\n",
    "\n",
    "        #validation\n",
    "        print(\"Epoch \" + str(epoch) + \" validating...\")\n",
    "        L = len(valLoader.datset)\n",
    "        pbar = tqdm(total = L)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            scoreDict = dict()\n",
    "            for i, batchData in enumerate(valLoader):\n",
    "                user = torch.LongTensor(batchData['user']).to(model.device)\n",
    "                posItems = torch.LongTensor(batchData['posItem']).to(model.device)\n",
    "                negItems = torch.LongTensor(batchData['negItem']).to(model.device)\n",
    "                budget = torch.FloatTensor(batchData['budget']).to(model.device)\n",
    "                posPrices = torch.FloatTensor(batchData['posPrice']).to(model.device)\n",
    "                negPrices = torch.FloatTensor(batchData['negPrice']).to(model.device)\n",
    "\n",
    "                items = torch.cat((posItems, negItems),1).view(-1)\n",
    "                prices = torch.cat((posPrices, negPrices),1).view(-1)\n",
    "                users = user.expand(items.shape[0])\n",
    "\n",
    "                out = model.forward(users,items)\n",
    "                scoreHeap = list()\n",
    "                for j in range(out.shape[0]):\n",
    "                    gt = False\n",
    "                    if j < posItems.shape[1]:\n",
    "                        gt = True\n",
    "                    if prices[j] > budget:\n",
    "                        continue\n",
    "                    heappush(scoreHeap, (1 - out[j].cpu().numpy(), (0 + items[j].cpu().numpy(), gt)))\n",
    "                scores = list()\n",
    "                candidate = len(scoreHeap)\n",
    "                for k in range(candidate):\n",
    "                    scores.append(heappop(scoreHeap))\n",
    "                pbar.update(1)\n",
    "                scoreDict[user[0]] = (scores, posItems.shape[1])\n",
    "        pbar.close()\n",
    "\n",
    "        valHistory.append(evaluation.ranking_performance(scoreDict,100))\n",
    "        valError = 1 - valHistory[-1][\"avg_ndcg\"][0]\n",
    "        valErrorList.append(valError)\n",
    "        improvement = np.abs(error - valError)\n",
    "        error = valError\n",
    "        if improvement < epsilon:\n",
    "            break\n",
    "\n",
    "        # test\n",
    "        print(\"starting test...\")\n",
    "        with torch.no_grad():\n",
    "            scoreDict = dict()\n",
    "            for i, batchData in enumerate(testLoader):\n",
    "                user = torch.LongTensor(batchData['user']).to(model.device)\n",
    "                posItems = torch.LongTensor(batchData['posItem']).to(model.device)\n",
    "                negItems = torch.LongTensor(batchData['negItem']).to(model.device)\n",
    "                budget = torch.FloatTensor(batchData['budget']).to(model.device)\n",
    "                posPrices = torch.FloatTensor(batchData['posPrice']).to(model.device)\n",
    "                negPrices = torch.FloatTensor(batchData['negPrice']).to(model.device)\n",
    "\n",
    "                items = torch.cat((posItems, negItems),1).view(-1)\n",
    "                prices = torch.cat((posPrices, negPrices),1).view(-1)\n",
    "                users = user.expand(items.shape[0])\n",
    "\n",
    "                out = model.forward(users,items)\n",
    "                scoreHeap = list()\n",
    "                for j in range(out.shape[0]):\n",
    "                    gt = False\n",
    "                    if j < posItems.shape[1]:\n",
    "                        gt = True\n",
    "                    if prices[j] > budget:\n",
    "                        continue\n",
    "                    heappush(scoreHeap, (1 - out[j].cpu().numpy(), (0 + items[j].cpu().numpy(), gt)))\n",
    "                scores = list()\n",
    "                candidate = len(scoreHeap)\n",
    "                for k in range(candidate):\n",
    "                    scores.append(heappop(scoreHeap))\n",
    "                pbar.update(1)\n",
    "                scoreDict[user[0]] = (scores, posItems.shape[1])\n",
    "        pbar.close()\n",
    "        testResult = evaluation.ranking_performance(scoreDict,100)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(\"Baby\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
