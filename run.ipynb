{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting pretrain the rating matrix...\n",
      "Epoch 2 training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9992e024bc64cf495e5ce6a84b9fe80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=132748), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-55048500b706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Baby\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-55048500b706>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(category)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchData\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0moptimizer_r\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m# get input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yingqiang/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yingqiang/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yingqiang/Documents/GitHub/Maximizing-Marginal-Utility-per-Dollar-for-Economic-Recommendation/data_loader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mprice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_price\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mnegItem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_neg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mnegPrice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrating_distribution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yingqiang/Documents/GitHub/Maximizing-Marginal-Utility-per-Dollar-for-Economic-Recommendation/data_loader.py\u001b[0m in \u001b[0;36mget_neg\u001b[0;34m(self, userid, itemid)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_neg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mneg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muserHist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "# from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from heapq import heappush, heappop\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import evaluation\n",
    "import data_loader\n",
    "from model import MF, MUD\n",
    "\n",
    "def main(category):\n",
    "    params = dict()\n",
    "    params['lr'] = 0.001\n",
    "    params['batch_size'] = 256\n",
    "    params['epoch_limit'] = 2\n",
    "    params['w_decay'] = 1\n",
    "    params['negNum'] = 1000\n",
    "    params['epsilon'] = 1e-4\n",
    "    params['n_neg'] = 4\n",
    "    params['l_size'] = 32\n",
    "    params['gpu']=False\n",
    "\n",
    "    train, val, test = data_loader.read_data(category)\n",
    "    item_price = data_loader.get_price(category)\n",
    "    item_related = data_loader.read_related(category)\n",
    "    distribution = data_loader.get_distribution(category)\n",
    "    trainset = data_loader.TransactionData(train, item_related, \\\n",
    "                item_price, distribution)\n",
    "    valset = data_loader.UserTransactionData(val, item_price, \\\n",
    "                trainset.itemNum, trainset.userHist)\n",
    "    testset = data_loader.UserTransactionData(test, item_price, \\\n",
    "                trainset.itemNum, trainset.userHist)\n",
    "\n",
    "    Rating = MF(userLen = trainset.userNum, itemLen = trainset.itemNum,\\\n",
    "             params = params)\n",
    "    optimizer_r = opt.SGD(Rating.parameters(), lr = params['lr'], \\\n",
    "            weight_decay = params['w_decay'])\n",
    "\n",
    "    criterion_rating = nn.MSELoss(reduction = 'sum')\n",
    "    criterion_risk = nn.MSELoss(reduction = 'sum')\n",
    "    criterion_MUD = nn.LogSoftmax(dim=0)\n",
    "\n",
    "    trainset.set_negN(params['n_neg'])\n",
    "    trainLoader = DataLoader(trainset, batch_size = params['batch_size'], \\\n",
    "                            shuffle = True, num_workers = 0)\n",
    "    valset.set_negN(1000)\n",
    "    valLoader = DataLoader(valset, batch_size = 1, \\\n",
    "                            shuffle = True, num_workers = 0)\n",
    "    testset.set_negN(1000)\n",
    "    testLoader = DataLoader(testset, batch_size = 1, \\\n",
    "                            shuffle = True, num_workers = 0)\n",
    "\n",
    "    epsilon = params['epsilon']\n",
    "    epoch = 1\n",
    "    error = np.float('inf')\n",
    "\n",
    "    print(\"starting pretrain the rating matrix...\")\n",
    "    while epoch < params['epoch_limit']:\n",
    "        runningLoss = []\n",
    "        epoch += 1\n",
    "        print(\"Epoch \" + str(epoch) + \" training...\")\n",
    "        L = len(trainLoader.dataset)\n",
    "        pbar = tqdm(total=L)\n",
    "        for i, batchData in enumerate(trainLoader):\n",
    "            optimizer_r.zero_grad()\n",
    "            # get input\n",
    "            users = torch.LongTensor(batchData['user']).to(Rating.device)\n",
    "            items = torch.LongTensor(batchData['item']).to(Rating.device)\n",
    "            pre_r = Rating.forward(users, items)\n",
    "            r = torch.FloatTensor(batchData['rating']).to(Rating.device)\n",
    "\n",
    "            loss = criterion_rating(pre_r, r)\n",
    "            loss.backward()\n",
    "            optimizer_r.step()\n",
    "            runningLoss.append(loss.item())\n",
    "\n",
    "            pbar.update(users.shape[0])\n",
    "        pbar.close()\n",
    "        meanMSE = np.mean(np.array(runningLoss))\n",
    "        improvement = np.abs(error - meanMSE)\n",
    "        error = meanMSE\n",
    "        if improvement <= epsilon:\n",
    "            print('pre-train stop early')\n",
    "            break\n",
    "\n",
    "    model = MUD(userLen = trainset.userNum, itemLen = trainset.itemNum,\\\n",
    "             distribution = distribution, item_price = item_price, \\\n",
    "             RMF = Rating, params = params)\n",
    "    optimizer = opt.SGD(model.parameters(), lr = params['lr'], \\\n",
    "            weight_decay = params['w_decay'])\n",
    "\n",
    "    epsilon = params['epsilon']\n",
    "    epoch = 0\n",
    "    error = np.float('inf')\n",
    "\n",
    "    trainErrorList = []\n",
    "    valErrorList = []\n",
    "    valHistory = []\n",
    "    explodeTempreture = 3\n",
    "    convergenceTempreture = 3\n",
    "    print(\"starting ROM model\")\n",
    "    while epoch < params['epoch_limit']:\n",
    "        epoch += 1\n",
    "        print(\"Epoch \" + str(epoch) + \" training...\")\n",
    "        L = len(trainLoader.dataset)\n",
    "        pbar = tqdm(total = L)\n",
    "        for i, batchData in enumerate(trainLoader):\n",
    "            optimizer.zero_grad()\n",
    "            # get input\n",
    "            users = torch.LongTensor(batchData['user']).to(model.device)\n",
    "#             print(users.shape)\n",
    "            items = torch.LongTensor(batchData['item']).to(model.device)\n",
    "#             print(items.shape)\n",
    "            negItems = torch.LongTensor(batchData['negItem']).to(model.device).reshape(-1)\n",
    "#             print(negItems.shape)\n",
    "            \n",
    "            nusers = users.view(-1,1) \n",
    "            nusers = nusers.expand(nusers.shape[0], params['n_neg']).reshape(-1)\n",
    "#             print(nusers.shape)\n",
    "            \n",
    "            \n",
    "            pOut = model.forward(users,items).view(-1,1)\n",
    "#             print(pOut.shape)\n",
    "            \n",
    "            nOut = model.forward(nusers, negItems)\n",
    "            nOut = nOut.reshape(-1,params[\"n_neg\"])\n",
    "#             print(nOut.shape)\n",
    "            \n",
    "            totalOut = torch.cat((pOut,nOut),dim=1)\n",
    "#             print (totalOut.shape)\n",
    "            \n",
    "            loss = torch.mean(criterion_MUD(totalOut)[:,0])\n",
    "#             print(loss.shape)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update(users.shape[0])\n",
    "        pbar.close()\n",
    "        \n",
    "        print(\"Epoch \" + str(epoch) + \" training risk...\")\n",
    "        pbar = tqdm(total = L)\n",
    "        for i, batchData in enumerate(trainLoader):\n",
    "            optimizer.zero_grad()\n",
    "            users = torch.LongTensor(batchData['user']).to(model.device)\n",
    "            items = torch.LongTensor(batchData['user']).to(model.device)\n",
    "\n",
    "            eu = model.EU(users,items)\n",
    "            ue = model.UE(users,items)\n",
    "\n",
    "            loss = criterion_risk(ue, eu)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update(users.shape[0])\n",
    "        pbar.close()\n",
    "\n",
    "        #validation\n",
    "        print(\"Epoch \" + str(epoch) + \" validating...\")\n",
    "        L = len(valLoader.dataset)\n",
    "        pbar = tqdm(total = L)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            scoreDict = dict()\n",
    "            for i, batchData in enumerate(valLoader):\n",
    "                user = torch.LongTensor(batchData['user']).to(model.device)\n",
    "                posItems = torch.LongTensor(batchData['posItem']).to(model.device)\n",
    "                negItems = torch.LongTensor(batchData['negItem']).to(model.device)\n",
    "                budget = torch.FloatTensor(batchData['budget']).to(model.device)\n",
    "                posPrices = torch.FloatTensor(batchData['posPrice']).to(model.device)\n",
    "                negPrices = torch.FloatTensor(batchData['negPrice']).to(model.device)\n",
    "\n",
    "                items = torch.cat((posItems, negItems),1).view(-1)\n",
    "                prices = torch.cat((posPrices, negPrices),1).view(-1)\n",
    "                users = user.expand(items.shape[0])\n",
    "\n",
    "                out = model.forward(users,items)\n",
    "                scoreHeap = list()\n",
    "                for j in range(out.shape[0]):\n",
    "                    gt = False\n",
    "                    if j < posItems.shape[1]:\n",
    "                        gt = True\n",
    "                    if prices[j] > budget:\n",
    "                        continue\n",
    "                    heappush(scoreHeap, (1 - out[j].cpu().numpy(), (0 + items[j].cpu().numpy(), gt)))\n",
    "                scores = list()\n",
    "                candidate = len(scoreHeap)\n",
    "                for k in range(candidate):\n",
    "                    scores.append(heappop(scoreHeap))\n",
    "                pbar.update(1)\n",
    "                scoreDict[user[0]] = (scores, posItems.shape[1])\n",
    "        pbar.close()\n",
    "\n",
    "        valHistory.append(evaluation.ranking_performance(scoreDict,100))\n",
    "        valError = 1 - valHistory[-1][\"avg_ndcg\"][0]\n",
    "        valErrorList.append(valError)\n",
    "        improvement = np.abs(error - valError)\n",
    "        error = valError\n",
    "        if improvement < epsilon:\n",
    "            break\n",
    "\n",
    "    # test\n",
    "    print(\"starting test...\")\n",
    "    L = len(testLoader.dataset)\n",
    "    pbar = tqdm(total = L)\n",
    "    with torch.no_grad():\n",
    "        scoreDict = dict()\n",
    "        for i, batchData in enumerate(testLoader):\n",
    "            user = torch.LongTensor(batchData['user']).to(model.device)\n",
    "            posItems = torch.LongTensor(batchData['posItem']).to(model.device)\n",
    "            negItems = torch.LongTensor(batchData['negItem']).to(model.device)\n",
    "            budget = torch.FloatTensor(batchData['budget']).to(model.device)\n",
    "            posPrices = torch.FloatTensor(batchData['posPrice']).to(model.device)\n",
    "            negPrices = torch.FloatTensor(batchData['negPrice']).to(model.device)\n",
    "\n",
    "            items = torch.cat((posItems, negItems),1).view(-1)\n",
    "            prices = torch.cat((posPrices, negPrices),1).view(-1)\n",
    "            users = user.expand(items.shape[0])\n",
    "\n",
    "            out = model.forward(users,items)\n",
    "            scoreHeap = list()\n",
    "            for j in range(out.shape[0]):\n",
    "                gt = False\n",
    "                if j < posItems.shape[1]:\n",
    "                    gt = True\n",
    "                if prices[j] > budget:\n",
    "                    continue\n",
    "                heappush(scoreHeap, (1 - out[j].cpu().numpy(), (0 + items[j].cpu().numpy(), gt)))\n",
    "            scores = list()\n",
    "            candidate = len(scoreHeap)\n",
    "            for k in range(candidate):\n",
    "                scores.append(heappop(scoreHeap))\n",
    "            pbar.update(1)\n",
    "            scoreDict[user[0]] = (scores, posItems.shape[1])\n",
    "    pbar.close()\n",
    "    testResult = evaluation.ranking_performance(scoreDict,100)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(\"Baby\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
