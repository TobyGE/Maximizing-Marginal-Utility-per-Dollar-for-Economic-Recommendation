{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import data_loader\n",
    "import torch.optim as opt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from model import MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MUD(nn.Module):\n",
    "    \"\"\"\n",
    "        - userLen: the number of users\n",
    "        - itemLen: the number of items\n",
    "        - params: the parameters dict used for constructing model\n",
    "            - l_size: latent dimension size\n",
    "            - gpu: True/False, whether using GPU\n",
    "            \n",
    "    \"\"\"\n",
    "    def __init__(self, userLen, itemLen, params):\n",
    "        super(MUD, self).__init__()\n",
    "        self.userNum = userLen\n",
    "        self.itemNum = itemLen\n",
    "        self.params = params\n",
    "        if 'gpu' in params and params['gpu'] == True:\n",
    "            self.device = 'cuda'\n",
    "        else:\n",
    "            self.device = 'cpu'\n",
    "\n",
    "        l_size = params['l_size']\n",
    "        \n",
    "        \"\"\"\n",
    "            Initialize  global bias,\n",
    "                        user bias,\n",
    "                        item bias,\n",
    "                        user embedding,\n",
    "                        item embedding\n",
    "        \"\"\"\n",
    "        self.globalBias = nn.Embedding(1,1)\n",
    "        self.uBias = nn.Embedding(userLen,1)\n",
    "        self.itemBias = nn.Embedding(itemLen,1)\n",
    "        self.uEmbed = nn.Embedding(userLen, l_size)\n",
    "        self.itemEmbed = nn.Embedding(itemLen, l_size)\n",
    "    \n",
    "    def forward(self, users, items, price, rating):\n",
    "        gB = self.globalBias.weight.data.expand(users.shape[0],1)\n",
    "        uE = self.uEmbed(users)\n",
    "        uB = self.uBias(users)\n",
    "        iE = self.itemEmbed(items)\n",
    "        iB = self.itemBias(items)\n",
    "        alpha = gB + uB + iB + torch.mul(uE, iE).sum(1).view(-1,1) \n",
    "        mud =  torch.mul(torch.tanh(rating),rating)/(2*torch.sigmoid(price))\n",
    "        return mud\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params[\"lr\"] = 0.01\n",
    "params[\"lr_decay\"] = 0.001\n",
    "params[\"batch_size\"] = 512\n",
    "params[\"epoch_limit\"] = 10\n",
    "params[\"w_decay\"] = 0.9\n",
    "params[\"momentum\"] = 0.0\n",
    "params[\"n_neg\"] = 1\n",
    "params[\"epsilon\"] = 1e-4\n",
    "# model parameters\n",
    "params[\"l_size\"] = 32\n",
    "params[\"gpu\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = data_loader.read_data(\"Baby\")\n",
    "price = data_loader.get_price(\"Baby\")\n",
    "related = data_loader.read_related(\"Baby\")\n",
    "trainset = data_loader.TransactionData(train,related,price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MUD(userLen = trainset.userNum, itemLen = trainset.itemNum, params = params)\n",
    "\n",
    "# optimizer: weight_decay correspond to L2 penalty\n",
    "optimizer = opt.SGD(model.parameters(), lr = params[\"lr\"], \\\n",
    "                    weight_decay = params[\"w_decay\"], momentum = params[\"momentum\"])\n",
    "\n",
    "# objectives: pairwise loss\n",
    "criterion = nn.LogSoftmax()\n",
    "\n",
    "# data loaders: train, val, test\n",
    "\n",
    "trainset.set_negN(params[\"n_neg\"])\n",
    "trainLoader = DataLoader(trainset, batch_size = params[\"batch_size\"], shuffle = True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab25154c37274e5a9c29abc3e374ad2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=132748), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658658206f5f4333acbe3827f4c7f96e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=132748), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b8ba43c2c719>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mpOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposPrice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposRating\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ranking score of positive samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mpOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpOut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mpOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpOut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpOut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_neg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# results are expanded to match negative samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-eb6685ea0af8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, users, items, price, rating)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0miE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemEmbed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0miB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemBias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgB\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0muB\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0miB\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mmud\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epsilon = params[\"epsilon\"]\n",
    "\n",
    "epoch = 0\n",
    "error = np.float(\"inf\")\n",
    "trainErrorList = []\n",
    "valErrorList = []\n",
    "valHistory = []\n",
    "explodeTempreture = 3\n",
    "convergenceTempreture = 3\n",
    "\n",
    "while epoch < params[\"epoch_limit\"]:\n",
    "    epoch = epoch + 1\n",
    "    \n",
    "    # epoch training\n",
    "    \n",
    "    print(\"Epoch \" + str(epoch) + \" training...\")\n",
    "    L = len(trainLoader.dataset)\n",
    "    pbar = tqdm(total = L)\n",
    "    runningLoss = list()\n",
    "    model.train()\n",
    "    for i, batchData in enumerate(trainLoader):\n",
    "        \n",
    "        # batch training\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # get input\n",
    "        users = torch.LongTensor(batchData['user']).to(model.device) # users\n",
    "        items = torch.LongTensor(batchData['item']).to(model.device) # positive samples\n",
    "        posPrice = torch.FloatTensor(batchData['price']).to(model.device)\n",
    "        posRating = torch.FloatTensor(batchData['rating']).to(model.device)\n",
    "\n",
    "        \n",
    "        npUsers = users.view(-1,1) \n",
    "        npUsers = npUsers.expand(npUsers.shape[0], params[\"n_neg\"]) # users expanded to match negative samples\n",
    "        negItems = torch.LongTensor(batchData['negItem']).to(model.device) # negative samples, default #=4\n",
    "        negPrice = torch.FloatTensor(batchData['negPrice']).to(model.device)\n",
    "        posRating = torch.FloatTensor(batchData['negRating']).to(model.device)\n",
    "        \n",
    "        # forward\n",
    "        pOut = model.forward(users, items, posPrice, posRating) # ranking score of positive samples\n",
    "        pOut = pOut.view(-1,1)\n",
    "        pOut = pOut.expand(pOut.shape[0], params[\"n_neg\"]) # results are expanded to match negative samples\n",
    "        pOut = pOut.reshape(-1)\n",
    "        \n",
    "        nOut = model.forward(npUsers.reshape(-1), negItems.reshape(-1)) # ranking score of negative samples\n",
    "\n",
    "        # loss\n",
    "        loss = criterion(pOut, nOut, torch.ones_like(nOut).to(model.device)) # pairwise loss\n",
    "        runningLoss.append(loss.item())\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "        \n",
    "        # progress report\n",
    "        pbar.update(users.shape[0])\n",
    "        # running loss update\n",
    "        if len(runningLoss) >= 50:\n",
    "            trainErrorList.append(np.mean(runningLoss))\n",
    "            runningLoss = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
